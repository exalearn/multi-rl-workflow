"""Example data types functions which illustrate the core operations of our workflow"""
from concurrent.futures import ProcessPoolExecutor
from pathlib import Path
from platform import node
from hashlib import sha512
from logging import getLogger
from random import random
from typing import Callable
import os

from redis import Redis

logger = getLogger(__name__)


# Data Types: Placeholders for now

class Sequence(str):
    """Sequence to be assessed"""


class Model(float):
    """Just a number"""


class MolecularDynamicsResult(str):
    """Result from a molecular dynamics calculation"""


# Globals used for warmable functions
loaded_model_path: Path | None = None  # Path to the model which is loaded
loaded_model: Model | None = None  # A loaded model


# Functions
def train_model(model_path: Path, database: Path, num_workers: int, redis_info: tuple[str, int]) -> tuple[Path, list[str]]:
    """Train a machine learning model cooperative with other workers

    Multiple instances of this function must be run across multiple workers.

    Args:
        model_path: Path to the current model
        database: Path to the training data
        num_workers: Number of cooperative workers to wait for
        redis_info: (Hostname, Port) for the redis server used to coordinate with other workers
    Returns:
        - Path to the new model
        - List of the hosts used for the computation
    """

    # Get all cooperative hosts
    key = sha512(str(model_path).encode()).hexdigest()[:16]
    hosts = get_hosts(key, num_workers, redis_info)
    logger.info(f'Received list of {len(hosts)} hosts that will cooperate in model training')

    # Do the magic
    return model_path, hosts


def policy_rollout(model_path: Path, num_episodes: int) -> list[Sequence]:
    """Generate a new batch of sequences given a policy

    Args:
        model_path: Path to the model being used to generate sequences
        num_episodes: Number of episodes over which to generate sequences
    Returns:
        Sequences generated by the model
    """
    global loaded_model
    global loaded_model_path

    # Load the model if it is new
    if loaded_model_path != model_path:
        from time import sleep
        sleep(0.5)
        loaded_model = model_path
        loaded_model_path = model_path

    # Generate sequences
    return ['aaa'] * num_episodes


def score_sequences(sequences: list[Sequence]) -> list[float]:
    """Generate a priority score for each sequence

    Args:
        sequences: List of sequences to evaluate
    Returns:
        Scores for each sequence
    """

    return [random() for _ in sequences]


def batch_run_molecular_dynamics(sequences: list[Sequence]) -> list[MolecularDynamicsResult]:
    """Run molecular dynamics on each member of a batch of sequences

    Args:
        sequences: Batch of sequences to be evaluated. Will run each of them in parallel with each other
    Returns:
        Scores for each
    """

    # Set the number of workers based on the batch size
    n_ranks = len(sequences)

    with ProcessPoolExecutor(n_ranks) as exc:
        # Submit all sequences
        futures = [
            exc.submit(_pin_then_run, run_molecular_dynamics, rank, n_ranks, seq)
            for rank, seq in enumerate(sequences)
        ]

        # Return all results
        return [f.result() for f in futures]


def run_molecular_dynamics(sequence: Sequence) -> MolecularDynamicsResult:
    """Perform a molecular dynamics calculation on a sequence

    Args:
        sequence: Sequence to be evaluated
    Returns:
        Result of the molecular dynamics
    """
    assert sequence is not None
    return MolecularDynamicsResult(os.environ.get("CUDA_VISIBLE_DEVICES"))


def _pin_then_run(function: Callable, rank: int, n_ranks: int, *args, **kwargs):
    """Pin a function to certain CPU threads and a single GPU then run the function

    Args:
        function: Function to be run
        rank: Rank of the worker running this function
        n_ranks: Total number of workers
        args: Positional arguments to pass to the function
        kwargs: Keyword arguments to pass to the function
    """
    # Borrowing some logic from Parsl for pinning: https://github.com/Parsl/parsl/blob/master/parsl/executors/high_throughput/process_worker_pool.py#L542
    # Pick a block of cores for this worker
    avail_cores = sorted(os.sched_getaffinity(0))  # Get the available processors
    cores_per_worker = len(avail_cores) // n_ranks
    assert cores_per_worker > 0, "Affinity does not work if there are more workers than cores"

    my_cores = avail_cores[cores_per_worker * rank:cores_per_worker * (rank + 1)]
    os.sched_setaffinity(0, my_cores)

    # Pin to a single GPU
    assert "CUDA_VISIBLE_DEVICES" not in os.environ, "CUDA_VISIBLE_DEVICES is already set"
    os.environ["CUDA_VISIBLE_DEVICES"] = str(rank)

    # Run the function
    try:
        return function(*args, **kwargs)
    finally:
        # Unset affinity
        os.sched_setaffinity(0, my_cores)
        os.environ.pop("CUDA_VISIBLE_DEVICES")


def get_hosts(key: str, num_workers: int, redis_info: tuple[str, int] = ('localhost', 6379)) -> list[str]:
    """Get the host names of all other workers

    Args:
        key: Key used to identify this pool of workers
        num_workers: Number of cooperative workers to wait for
        redis_info: (Hostname, Port) for the redis server used to coordinate with other workers
    """
    # Make the redis client
    host, port = redis_info
    redis = Redis(host=host, port=port)

    # Immediately subscribe to the channel
    pubsub = redis.pubsub()
    channel = f'pubsub-{key}'
    pubsub.subscribe(channel)

    # Append my hostname to the list
    hostname = node()
    list_key = f'hosts-{key}'
    rank = redis.lpush(list_key, hostname)
    logger.info(f'I am rank {rank} for {key}')

    # Either wait for full list or wait
    if rank < num_workers:
        # Wait for someone else to publish the list
        hosts = None
        for message in pubsub.listen():
            if message['type'] == 'message':
                hosts = message['data'].decode().split(":")
                break
        pubsub.unsubscribe()
    elif rank == num_workers:
        # Send the lists of hosts to everyone else
        hosts = redis.lrange(list_key, 0, rank + 1)
        hosts = [h.decode() for h in hosts]

        redis.delete(list_key)  # No longer needed
        redis.publish(channel, ":".join(hosts))  # Everyone should be subscribed at this point
    else:
        raise ValueError(f'Received rank #{rank}, but there should only be {num_workers} ranks')

    return hosts
